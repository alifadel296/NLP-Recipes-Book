{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIunAcCa7Egu"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmZ_0rFb7Ypj"
      },
      "outputs": [],
      "source": [
        "! pip install nltk tensorflow pandas numpy matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCJI0qGuKcnC",
        "outputId": "eca88635-14c5-49cb-93ae-9ec50f5cea1b"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpDulDqKo7nG"
      },
      "source": [
        "# Mounting data from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrNeeurbXOrO",
        "outputId": "1911cdcf-ffe4-450d-b21e-b1575cf29b90"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRLvg83Po7nG"
      },
      "source": [
        "# Read the data and preprocessing it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGzFb3alYpUg"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Text Classification/spam.csv' , encoding = 'ISO-8859-1')\n",
        "data.rename(columns = {'v1' : 'Target' , 'v2' : 'Text'} , inplace = True)\n",
        "data= data[['Target' , 'Text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "DyyKZgM1u1bP",
        "outputId": "ababc80e-158b-496a-cf9f-0eb4bef52920"
      },
      "outputs": [],
      "source": [
        "# Removing stop words\n",
        "stopwords_list = stopwords.words('english')\n",
        "data['Text'] = data['Text'].apply(lambda x : \" \".join(x for word in x.split() if word not in stopwords_list))\n",
        "data['Text'] = data['Text'].apply(lambda x : re.sub('[!@#$:).;,?&]','',x.lower()))\n",
        "data['Text']= data['Text'].apply(lambda x : re.sub(' ', ' ' , x))\n",
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "9SxTxExsKnlY",
        "outputId": "77da567b-de14-459e-9afc-7b2c1ff552f8"
      },
      "outputs": [],
      "source": [
        "# Check the null valuse\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y98xMKXxGAHv"
      },
      "outputs": [],
      "source": [
        "# Train and test split with 80:20 ratio\n",
        "xTrain , xTest , yTrain , yTest = train_test_split(data['Text'] , data['Target'] , test_size= 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO4FoPjuo7nH"
      },
      "source": [
        "# Tokenization and padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKHRAUzmGo3R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Define the sequence length, max number of words and embedding dimensions\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "# Get the frequently occurring words\n",
        "tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(xTrain)\n",
        "train_sequences = tokenizer.texts_to_sequences(xTrain)\n",
        "test_sequences = tokenizer.texts_to_sequences(xTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_n7iYMBGqEu"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# dictionary containing words and their index\n",
        "word_index = tokenizer.word_index\n",
        "# Padding the sequences to 300 length\n",
        "train_data = pad_sequences(train_sequences , maxlen = MAX_SEQUENCE_LENGTH)\n",
        "test_data = pad_sequences(test_sequences , maxlen= MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKjuKJIXo7nH"
      },
      "source": [
        "# Encoding the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WekO3EjqJnU9",
        "outputId": "76e03b21-07a8-4d00-f9b6-48d048829c13"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(yTrain)\n",
        "train_labels = le.transform(yTrain)\n",
        "test_labels = le.transform(yTest)\n",
        "test_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWmMNpWKhgt",
        "outputId": "713844ab-fe39-49e1-fca6-d41c0a0e3718"
      },
      "outputs": [],
      "source": [
        "# One hot encoding for the labels\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "encoded_train_labels = to_categorical(np.asarray(train_labels))\n",
        "encoded_test_labels = to_categorical(np.asarray(test_labels))\n",
        "print(encoded_train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoV8Pct6o7nI"
      },
      "source": [
        "# Building the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdUZ35ZFLVqU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, SimpleRNN\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import initializers, regularizers, constraints,optimizers, layers\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Dropout,BatchNormalization , SimpleRNN\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZuVS1uyo7nI"
      },
      "source": [
        "# Building First Model (1-D CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOtrdadkNHMb",
        "outputId": "f28474b0-0cea-40b9-ea2f-fa23cc1b3224"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS , EMBEDDING_DIM , input_length = MAX_SEQUENCE_LENGTH))\n",
        "model.add(Dropout(0.5))\n",
        "for i in range(2):\n",
        "  model.add(Conv1D(128 , 5, activation= 'relu'))\n",
        "  model.add(MaxPooling1D(5))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units= 128 , activation= 'relu'))\n",
        "model.add(Dense(units= 2 , activation= 'softmax'))\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics=['acc'])\n",
        "  model.fit(train_data , encoded_train_labels , batch_size =8 , epochs = 5, validation_data=(test_data , encoded_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnORiHS8QLqT",
        "outputId": "47d2977c-1817-4854-ef3b-bec23344dc08"
      },
      "outputs": [],
      "source": [
        "predictaion = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvlFC7zwSoAT",
        "outputId": "b9a5a2b3-d959-4d46-9943-7fae8d9a66d4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(encoded_test_labels , predictaion.round()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBhpDqPpo7nI"
      },
      "source": [
        "# Build the second model (Simple RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_HhIp5rS-PU",
        "outputId": "68954c4f-c99b-47c7-f7ca-a62351c70645"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS , EMBEDDING_DIM , input_length= MAX_SEQUENCE_LENGTH))\n",
        "model.add(SimpleRNN(2 , input_shape = (None , 1)))\n",
        "model.add(Dense(50 , activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2 , activation = 'softmax'))\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics=['acc'])\n",
        "  model.fit(train_data , encoded_train_labels , batch_size =16 , epochs = 5, validation_data=(test_data , encoded_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YesJK_1aZffh",
        "outputId": "d6f81b67-cbc5-4f63-a7b9-06977e097354"
      },
      "outputs": [],
      "source": [
        "predictaion = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWoxwbF1ZioJ",
        "outputId": "28a79245-9aec-48c9-d59b-815f44dd84ef"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(encoded_test_labels , predictaion.round()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07gXj69Eo7nI"
      },
      "source": [
        "# Building the Third model (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqliRVvKZkiV",
        "outputId": "034a9a66-5928-44c1-85b8-4720df3c9e67"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS , EMBEDDING_DIM ,input_length = MAX_SEQUENCE_LENGTH))\n",
        "model.add(LSTM(units = 2,activation='relu' , return_sequences= True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2 , activation='softmax'))\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics=['acc'])\n",
        "  model.fit(train_data , encoded_train_labels , batch_size =8 , epochs = 5, validation_data=(test_data , encoded_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqX-PEJ9o7nJ",
        "outputId": "108b8378-39a8-4765-e81a-a541aa96aded"
      },
      "outputs": [],
      "source": [
        "predictaion = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk8SpKQviHPU",
        "outputId": "25813a85-299a-4e4b-d248-58279295c3f8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(encoded_test_labels , predictaion.round()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1ylkGyFo7nJ"
      },
      "source": [
        "# Building the Fourth model (Bidirectional LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us2zomKEiJR8",
        "outputId": "5cfefd99-120e-4b92-847b-c7643e08f382"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS , EMBEDDING_DIM ,input_length = MAX_SEQUENCE_LENGTH))\n",
        "model.add(Bidirectional(LSTM(units = 2,activation='relu' , return_sequences= True , dropout = 0.1)))\n",
        "model.add(Conv1D (16 , kernel_size =3))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(50 , activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(2 ,activation = 'softmax'))\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics=['acc'])\n",
        "  model.fit(train_data , encoded_train_labels , batch_size =8 , epochs = 5, validation_data=(test_data , encoded_test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgUSeXrejoj5",
        "outputId": "cbf988b1-183d-4d51-9d64-77ae5bdac4b1"
      },
      "outputs": [],
      "source": [
        "predictaion = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PqPCc6sj262",
        "outputId": "4e25ce09-3540-45a9-bc80-36d2203c759d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(encoded_test_labels , predictaion.round()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "work",
      "language": "python",
      "name": "work"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
